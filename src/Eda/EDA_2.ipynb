{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Description\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Second EDA for catbase database.\n",
                "\n",
                "Focuses on analyzing data during data processing.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Start\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pathlib import Path\n",
                "from typing import Dict\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import plotly.express as px\n",
                "from dash import Dash, dcc, html\n",
                "\n",
                "from src.utils import load_data_config"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Definitons\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_paths, column_types = load_data_config()\n",
                "data_path_initial = Path(data_paths[\"initial\"])\n",
                "data_path_helper = Path(data_paths[\"helper\"])\n",
                "data_path_processed = Path(data_paths[\"processed\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# EDA\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Before data processing\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Missing values\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_missing_values():\n",
                "    all_cats_df = pd.read_csv(f\"{data_path_initial}/all_cats.csv\", dtype=column_types, low_memory=False)\n",
                "\n",
                "    missing_values = all_cats_df.isnull().mean() * 100\n",
                "    missing_values = missing_values.sort_values(ascending=False)\n",
                "\n",
                "    app = Dash(__name__)\n",
                "\n",
                "    fig = px.bar(\n",
                "        x=missing_values.index,\n",
                "        y=missing_values.values,\n",
                "        title=\"Percentage of Missing Values by Column\",\n",
                "        labels={\"x\": \"Columns\", \"y\": \"Missing Values (%)\"},\n",
                "    )\n",
                "\n",
                "    fig.update_traces(\n",
                "        text=missing_values.values.round(0),\n",
                "    )\n",
                "\n",
                "    app.layout = html.Div([dcc.Graph(id=\"missing-values-graph\", figure=fig)])\n",
                "\n",
                "    app.run_server(debug=True)\n",
                "\n",
                "\n",
                "show_missing_values()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Same country\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def same_country(row: pd.Series) -> int:\n",
                "    \"\"\"\n",
                "    Check if the country of origin is the same as the current country.\n",
                "\n",
                "    :param row: A row from the DataFrame.\n",
                "    :returns: 1 if the countries are same, 0 otherwise.\n",
                "    \"\"\"\n",
                "    if row[\"country_origin\"] == row[\"country_current\"]:\n",
                "        return 1\n",
                "    if pd.isna(row[\"country_origin\"]) and pd.isna(row[\"country_current\"]):\n",
                "        return 1\n",
                "    return 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_country_check():\n",
                "    all_cats_df = pd.read_csv(\n",
                "        f\"{data_path_initial}/all_cats.csv\",\n",
                "        usecols=[\"country_origin\", \"country_current\"],\n",
                "        dtype=column_types,\n",
                "        low_memory=False,\n",
                "    )\n",
                "\n",
                "    all_cats_df[\"country_check\"] = all_cats_df.apply(same_country, axis=1)\n",
                "\n",
                "    value_counts = all_cats_df[\"country_check\"].value_counts()\n",
                "    percentages = all_cats_df[\"country_check\"].value_counts(normalize=True) * 100\n",
                "\n",
                "    print(\"\\nCountry Origin vs Current Country Analysis:\")\n",
                "    print(\"-\" * 45)\n",
                "    for value in value_counts.index:\n",
                "        count = value_counts[value]\n",
                "        percentage = percentages[value]\n",
                "        status = \"Same country\" if value else \"Different country\"\n",
                "        print(f\"{status}: {count:,} cats ({percentage:.1f}%)\")\n",
                "\n",
                "\n",
                "show_country_check()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## During data processing phase 3\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Countries\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_cats_df = pd.read_csv(\n",
                "    f\"{data_path_processed}/all_cats_first_fixes.csv\",\n",
                "    usecols=[\"cat_id\", \"country_origin\", \"country_current\", \"country_origin_name\", \"country_current_name\"],\n",
                "    dtype=column_types,\n",
                "    low_memory=False,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "origin_mismatch = all_cats_df[\n",
                "    (all_cats_df[\"country_origin_name\"] == \"unknown\")\n",
                "    & (all_cats_df[\"country_origin\"] != \"unknown\")\n",
                "    & (~all_cats_df[\"country_origin\"].isna())\n",
                "]\n",
                "\n",
                "current_mismatch = all_cats_df[\n",
                "    (all_cats_df[\"country_current_name\"] == \"unknown\")\n",
                "    & (all_cats_df[\"country_current\"] != \"unknown\")\n",
                "    & (~all_cats_df[\"country_current\"].isna())\n",
                "]\n",
                "\n",
                "print(\"Country Origin codes with 'unknown' country names:\")\n",
                "if len(origin_mismatch) > 0:\n",
                "    print(origin_mismatch[\"country_origin\"].value_counts())\n",
                "else:\n",
                "    print(\"None found\")\n",
                "\n",
                "print(\"\\nCountry Current codes with 'unknown' country names:\")\n",
                "if len(current_mismatch) > 0:\n",
                "    print(current_mismatch[\"country_current\"].value_counts())\n",
                "else:\n",
                "    print(\"None found\")\n",
                "\n",
                "if len(origin_mismatch) > 0:\n",
                "    origin_percentage = len(origin_mismatch) / len(all_cats_df) * 100\n",
                "    print(\n",
                "        f\"\\nPercentage of rows with 'unknown' country_origin_name but valid country_origin: {origin_percentage:.2f}%\"\n",
                "    )\n",
                "\n",
                "if len(current_mismatch) > 0:\n",
                "    current_percentage = len(current_mismatch) / len(all_cats_df) * 100\n",
                "    print(\n",
                "        f\"Percentage of rows with 'unknown' country_current_name but valid country_current: {current_percentage:.2f}%\"\n",
                "    )\n",
                "\n",
                "unique_origin_mismatch = origin_mismatch[\"country_origin\"].unique()\n",
                "unique_current_mismatch = current_mismatch[\"country_current\"].unique()\n",
                "\n",
                "print(\"\\nUnique country_origin codes with 'unknown' country names:\")\n",
                "if len(unique_origin_mismatch) > 0:\n",
                "    print(unique_origin_mismatch)\n",
                "\n",
                "print(\"\\nUnique country_current codes with 'unknown' country names:\")\n",
                "if len(unique_current_mismatch) > 0:\n",
                "    print(unique_current_mismatch)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Registration_number_current\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_cats_df = pd.read_csv(f\"{data_path_processed}/all_cats_first_fixes.csv\", dtype=column_types, low_memory=False)\n",
                "all_cats_df[\"src_db\"].unique().tolist()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Split data based on \"src_db\" column\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_db_dataframes(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
                "    \"\"\"\n",
                "    Create separate DataFrames for each src_db in the DataFrame.\n",
                "\n",
                "    :param df: DataFrame containing the data.\n",
                "    :returns: Dictionary where keys are src_db names and values are DataFrames.\n",
                "    \"\"\"\n",
                "    src_db_list = [\n",
                "        \"Finland\",\n",
                "        \"German Database\",\n",
                "        \"Norway\",\n",
                "        \"pawpeds\",\n",
                "        \"DB Polska\",\n",
                "        \"sibcat\",\n",
                "        \"FFS_SK\",\n",
                "        \"SVERAK\",\n",
                "        \"TOP-CAT\",\n",
                "        \"unknown\",\n",
                "    ]\n",
                "\n",
                "    src_db_frames = {}\n",
                "\n",
                "    for db in src_db_list:\n",
                "        filtered_df = df[df[\"src_db\"] == db][[\"registration_number_current\"]]\n",
                "\n",
                "        filtered_df = filtered_df.drop_duplicates(subset=[\"registration_number_current\"])\n",
                "        filtered_df = filtered_df.sort_values(by=[\"registration_number_current\"])\n",
                "        filtered_df = filtered_df.reset_index(drop=True)\n",
                "\n",
                "        src_db_frames[db] = filtered_df\n",
                "\n",
                "        print(f\"{db}: {len(filtered_df)} records\")\n",
                "\n",
                "    return src_db_frames\n",
                "\n",
                "\n",
                "src_db_frames = create_db_dataframes(all_cats_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def output_dataframes(src_db_frames: Dict[str, pd.DataFrame], output_path=\"../../output/reg_num_initial\") -> None:\n",
                "    \"\"\"\n",
                "    Output the dataframes to CSV files.\n",
                "\n",
                "    :param src_db_frames: Dictionary of DataFrames to output.\n",
                "    \"\"\"\n",
                "    os.makedirs(\"../../output\", exist_ok=True)\n",
                "    os.makedirs(output_path, exist_ok=True)\n",
                "\n",
                "    for db_name, df in src_db_frames.items():\n",
                "        if len(df) == 1 and df[\"registration_number_current\"].iloc[0] == \"unknown\":\n",
                "            continue\n",
                "\n",
                "        filename = f\"{output_path}/{db_name.replace(' ', '_').replace('-', '_')}.csv\"\n",
                "        df.to_csv(filename, index=False)\n",
                "\n",
                "\n",
                "output_dataframes(src_db_frames)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Export only \"registration_number_current\" that seems to resemble actual words\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def export_only_words(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    Export only registration_numbers_current that could mean some words.\n",
                "\n",
                "    :param df: DataFrame to filter.\n",
                "    :returns: DataFrame with only words.\n",
                "    \"\"\"\n",
                "\n",
                "    output_path = \"../../output/reg_num_initial/only_words.csv\"\n",
                "\n",
                "    os.makedirs(\"../../output\", exist_ok=True)\n",
                "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
                "\n",
                "    filtered_df = df[~df[\"registration_number_current\"].str.isnumeric()]\n",
                "    filtered_df = filtered_df[~filtered_df[\"registration_number_current\"].str.contains(r\"[\\/\\-\\.\\_\\(\\)№]\")]\n",
                "    filtered_df.to_csv(output_path, index=False)\n",
                "\n",
                "\n",
                "export_only_words(src_db_frames[\"TOP-CAT\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def export_reg_num_with_parentheses(df: pd.DataFrame) -> None:\n",
                "    \"\"\"\n",
                "    Export all registration_number_current that have parentheses.\n",
                "\n",
                "    :param df: DataFrame to filter.\n",
                "    \"\"\"\n",
                "\n",
                "    output_path = \"../../output/reg_num_initial/registration_numbers_with_parentheses.csv\"\n",
                "\n",
                "    os.makedirs(\"../../output\", exist_ok=True)\n",
                "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
                "\n",
                "    filtered_df = df[df[\"registration_number_current\"].str.contains(r\"[\\(\\)]\", na=False)]\n",
                "    filtered_df = filtered_df[[\"registration_number_current\"]].drop_duplicates()\n",
                "    filtered_df = filtered_df.sort_values(by=\"registration_number_current\").reset_index(drop=True)\n",
                "    filtered_df.to_csv(output_path, index=False)\n",
                "\n",
                "\n",
                "export_reg_num_with_parentheses(all_cats_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fixed_cats = pd.read_csv(\n",
                "    f\"{data_path_processed}/all_cats_done.csv\",\n",
                "    dtype=column_types,\n",
                "    low_memory=False,\n",
                ")\n",
                "\n",
                "src_db_frames = create_db_dataframes(fixed_cats)\n",
                "output_dataframes(src_db_frames, output_path=\"../../output/reg_num_fixes\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "unknown_count = all_cats_df[\"registration_number_current\"].value_counts().get(\"unknown\", 0)\n",
                "print(f\"Number of 'unknown' values in 'registration_number_current': {unknown_count}\")\n",
                "\n",
                "unknown_count_fixed = fixed_cats[\"registration_number_current\"].value_counts().get(\"unknown\", 0)\n",
                "print(f\"Number of 'unknown' values in 'registration_number_current' after fixing: {unknown_count_fixed}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Correct mother/father names\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_cats_df = pd.read_csv(\n",
                "    f\"{data_path_initial}/all_cats.csv\",\n",
                "    usecols=[\"id\", \"father_id\", \"mother_id\"],\n",
                "    dtype=column_types,\n",
                "    low_memory=False,\n",
                ")\n",
                "\n",
                "all_cats_df[\"father_check\"] = (all_cats_df[\"father_id\"] == all_cats_df[\"id\"]).fillna(False)\n",
                "all_cats_df[\"mother_check\"] = (all_cats_df[\"mother_id\"] == all_cats_df[\"id\"]).fillna(False)\n",
                "\n",
                "father_check_counts = all_cats_df[\"father_check\"].value_counts()\n",
                "mother_check_counts = all_cats_df[\"mother_check\"].value_counts()\n",
                "\n",
                "print(\"\\nFather and Mother Check Analysis:\")\n",
                "for value in father_check_counts.index:\n",
                "    count = father_check_counts[value]\n",
                "    status = \"Invalid\" if value else \"Valid\"\n",
                "    print(f\"Father check: {count:,} cats ({status})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Unknown cat names\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_cats_df = pd.read_csv(\n",
                "    f\"{data_path_initial}/all_cats.csv\",\n",
                "    usecols=[\"id\", \"name\"],\n",
                "    dtype=column_types,\n",
                "    low_memory=False,\n",
                ")\n",
                "\n",
                "all_cats_df[\"name\"] = all_cats_df[\"name\"].fillna(\"Unknown cat name\")\n",
                "all_cats_df[\"name_prefix\"] = all_cats_df[\"name\"].str.split(\" \").str[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "unique_prefixes = sorted(all_cats_df[\"name_prefix\"].unique())\n",
                "\n",
                "short_prefixes = [prefix for prefix in unique_prefixes if len(prefix) < 5]\n",
                "\n",
                "output_dir = \"../../output\"\n",
                "os.makedirs(output_dir, exist_ok=True)\n",
                "output_path = os.path.join(output_dir, \"unique_name_prefixes.txt\")\n",
                "\n",
                "try:\n",
                "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
                "        for prefix in short_prefixes:\n",
                "            f.write(prefix + \"\\n\")\n",
                "except Exception as e:\n",
                "    print(f\"Error writing to file: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "Prefix\t    Language\n",
                "\"of\"\t    English\n",
                "\"de\"\t    French/Spanish/Portuguese\n",
                "\"van\"\t    Dutch\n",
                "\"von\"\t    German\n",
                "\"z\"\t        Polish/Czech\n",
                "\"del\"\t    Spanish/Italian\n",
                "\"di\"\t    Italian\n",
                "\"od\"\t    Croatian/Serbian/Bosnian\n",
                "\"iz\" (из)\tRussian\n",
                "\"aus\"\t    German\n",
                "\"el\"\t    Arabic/Spanish\n",
                "\"al\"\t    Arabic\n",
                "\"ot\" (от)\tRussian\n",
                "\"\"\"\n",
                "\n",
                "prefix_list = [\"of\", \"de\", \"van\", \"von\", \"z\", \"del\", \"di\", \"od\", \"iz\", \"el\", \"al\", \"ot\", \"auf\", \"aus\", \"из\", \"от\"]\n",
                "prefix_counts = all_cats_df[\"name_prefix\"].value_counts()\n",
                "prefix_counts = prefix_counts[prefix_counts.index.isin(prefix_list)]\n",
                "prefix_counts = prefix_counts.reset_index()\n",
                "\n",
                "prefix_counts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Prefixes in dataset:\")\n",
                "for _, row in prefix_counts.iterrows():\n",
                "    print(row[\"name_prefix\"])\n",
                "\n",
                "print(\"-\" * 45)\n",
                "print(\"Prefixes not in dataset:\")\n",
                "for prefix in prefix_list:\n",
                "    if prefix not in prefix_counts[\"name_prefix\"].values:\n",
                "        print(prefix)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## After phase 3\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Missing values\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Missing values (NA, NaN, None).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_missing_values():\n",
                "    all_cats_df = pd.read_csv(\n",
                "        f\"{data_path_processed}/all_cats_first_fixes.csv\", dtype=column_types, low_memory=False\n",
                "    )\n",
                "\n",
                "    missing_values = all_cats_df.isnull().mean() * 100\n",
                "    missing_values = missing_values.sort_values(ascending=False)\n",
                "\n",
                "    app = Dash(__name__)\n",
                "\n",
                "    fig = px.bar(\n",
                "        x=missing_values.index,\n",
                "        y=missing_values.values,\n",
                "        title=\"Percentage of Missing Values by Column\",\n",
                "        labels={\"x\": \"Columns\", \"y\": \"Missing Values (%)\"},\n",
                "    )\n",
                "\n",
                "    fig.update_traces(\n",
                "        text=missing_values.values.round(0),\n",
                "    )\n",
                "\n",
                "    app.layout = html.Div([dcc.Graph(id=\"missing-values-graph\", figure=fig)])\n",
                "    app.run_server(debug=True)\n",
                "\n",
                "\n",
                "show_missing_values()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Missing values (unknown, -1, ...)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_missing_values():\n",
                "    all_cats_df = pd.read_csv(\n",
                "        f\"{data_path_processed}/all_cats_first_fixes.csv\", dtype=column_types, low_memory=False\n",
                "    )\n",
                "\n",
                "    date_placeholder = \"1111-11-11 00:00:00\"\n",
                "    unknown_placeholder = \"unknown\"\n",
                "    name_placeholder = \"Unknown cat name\"\n",
                "    number_placeholder = -1\n",
                "\n",
                "    date_columns = [\"date_of_birth\"]\n",
                "    unknown_columns = [\n",
                "        \"gender\",\n",
                "        \"registration_number_current\",\n",
                "        \"src_db\",\n",
                "        \"cattery\",\n",
                "        \"breed_code\",\n",
                "        \"extracted_breed\",\n",
                "        \"colour_code\",\n",
                "        \"colour_definition\",\n",
                "        \"full_breed_name\",\n",
                "        \"group\",\n",
                "        \"category\",\n",
                "        \"country_origin\",\n",
                "        \"country_current\",\n",
                "        \"country_origin_name\",\n",
                "        \"country_current_name\",\n",
                "        \"title_after\",\n",
                "        \"title_before\",\n",
                "        \"chip\",\n",
                "    ]\n",
                "    name_columns = [\"name\"]\n",
                "    number_columns = [\"father_id\", \"mother_id\"]\n",
                "\n",
                "    missing_percentages = {}\n",
                "\n",
                "    for col in date_columns:\n",
                "        if col in all_cats_df.columns:\n",
                "            missing_percentages[col] = (all_cats_df[col] == date_placeholder).mean() * 100\n",
                "\n",
                "    for col in unknown_columns:\n",
                "        if col in all_cats_df.columns:\n",
                "            missing_percentages[col] = (all_cats_df[col] == unknown_placeholder).mean() * 100\n",
                "\n",
                "    for col in name_columns:\n",
                "        if col in all_cats_df.columns:\n",
                "            missing_percentages[col] = (all_cats_df[col] == name_placeholder).mean() * 100\n",
                "\n",
                "    for col in number_columns:\n",
                "        if col in all_cats_df.columns:\n",
                "            missing_percentages[col] = (all_cats_df[col] == number_placeholder).mean() * 100\n",
                "\n",
                "    missing_df = pd.DataFrame(\n",
                "        {\n",
                "            \"column\": list(missing_percentages.keys()),\n",
                "            \"percent_missing\": list(missing_percentages.values()),\n",
                "        }\n",
                "    )\n",
                "\n",
                "    missing_df = missing_df[missing_df[\"percent_missing\"] > 0]\n",
                "\n",
                "    missing_df = missing_df.sort_values(by=\"percent_missing\", ascending=False)\n",
                "\n",
                "    app = Dash(__name__)\n",
                "\n",
                "    fig = px.bar(\n",
                "        missing_df,\n",
                "        x=\"column\",\n",
                "        y=\"percent_missing\",\n",
                "        title=\"Missing Values by Column\",\n",
                "        labels={\n",
                "            \"column\": \"Columns\",\n",
                "            \"percent_missing\": \"Missing Values (%)\",\n",
                "        },\n",
                "        hover_data=[\"percent_missing\"],\n",
                "    )\n",
                "\n",
                "    fig.update_layout(xaxis_tickangle=-45, height=600)\n",
                "    fig.update_traces(texttemplate=\"%{y:.1f}%\", textposition=\"outside\")\n",
                "    app.layout = html.Div(\n",
                "        [\n",
                "            dcc.Graph(id=\"missing-values-graph\", figure=fig),\n",
                "        ]\n",
                "    )\n",
                "\n",
                "    app.run_server(debug=True)\n",
                "\n",
                "\n",
                "show_missing_values()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## During phase 5\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def display_country_code_mappings() -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    Display a mapping between country names and all their associated codes\n",
                "    found in the dataset.\n",
                "    \"\"\"\n",
                "    df = pd.read_csv(\n",
                "        f\"{data_path_processed}/all_cats_done.csv\",\n",
                "        usecols=[\"country_origin_name\", \"country_origin\", \"country_current_name\", \"country_current\"],\n",
                "        dtype=column_types,\n",
                "        low_memory=False,\n",
                "    )\n",
                "\n",
                "    name_to_codes = {}\n",
                "\n",
                "    for name, code in zip(df[\"country_origin_name\"], df[\"country_origin\"]):\n",
                "        if name != \"unknown\" and code != \"unknown\":\n",
                "            if name not in name_to_codes:\n",
                "                name_to_codes[name] = set()\n",
                "            name_to_codes[name].add(code)\n",
                "\n",
                "    for name, code in zip(df[\"country_current_name\"], df[\"country_current\"]):\n",
                "        if name != \"unknown\" and code != \"unknown\":\n",
                "            if name not in name_to_codes:\n",
                "                name_to_codes[name] = set()\n",
                "            name_to_codes[name].add(code)\n",
                "\n",
                "    result_data = []\n",
                "    for name in sorted(name_to_codes.keys()):\n",
                "        result_data.append({\"country_name\": name, \"country_codes\": \", \".join(sorted(name_to_codes[name]))})\n",
                "\n",
                "    return pd.DataFrame(result_data)\n",
                "\n",
                "\n",
                "display_country_code_mappings()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Later\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_id_gaps():\n",
                "    \"\"\"\n",
                "    Analyze if there are gaps in the 'id' column sequence.\n",
                "    Reports statistics about gaps and visualizes them if present.\n",
                "    \"\"\"\n",
                "    print(\"Loading data...\")\n",
                "    all_cats_df = pd.read_csv(\n",
                "        f\"{data_path_initial}/all_cats.csv\", usecols=[\"id\"], dtype=column_types, low_memory=False\n",
                "    )\n",
                "\n",
                "    all_cats_df = all_cats_df.sort_values(by=\"id\").drop_duplicates()\n",
                "\n",
                "    ids = all_cats_df[\"id\"].unique()\n",
                "    ids.sort()\n",
                "\n",
                "    expected_ids = np.arange(ids.min(), ids.max() + 1)\n",
                "    missing_ids = np.setdiff1d(expected_ids, ids)\n",
                "\n",
                "    print(\"\\nID Range Analysis:\")\n",
                "    print(f\"Min ID: {ids.min():,}\")\n",
                "    print(f\"Max ID: {ids.max():,}\")\n",
                "    print(f\"Total unique IDs: {len(ids):,}\")\n",
                "    print(f\"Expected IDs in range: {len(expected_ids):,}\")\n",
                "\n",
                "    if len(missing_ids) > 0:\n",
                "        gap_percentage = (len(missing_ids) / len(expected_ids)) * 100\n",
                "        print(\"\\nGap Analysis:\")\n",
                "        print(f\"Number of gaps: {len(missing_ids):,} ({gap_percentage:.2f}% of ID range)\")\n",
                "    else:\n",
                "        print(\"\\nNo gaps found in the ID sequence!\")\n",
                "\n",
                "\n",
                "analyze_id_gaps()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "BachelorProject_Babiar",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
