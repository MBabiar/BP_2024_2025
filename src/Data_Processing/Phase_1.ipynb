{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Description\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-   Get initial data from relation database and export them to csv for easier manipulation.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Start\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "import pandas as pd\n",
                "import psycopg2\n",
                "from sqlalchemy import create_engine\n",
                "\n",
                "from src.utils import load_data_config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_paths, column_types = load_data_config()\n",
                "data_path_initial = Path(data_paths[\"initial\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_engine_from_config():\n",
                "    with open(\"../../config/config.json\", \"r\") as file:\n",
                "        config = json.load(file)\n",
                "\n",
                "    running_in_docker = os.environ.get(\"RUNNING_IN_DOCKER\", \"false\").lower() == \"true\"\n",
                "\n",
                "    db_config = config[\"relational_database_docker\"] if running_in_docker else config[\"relational_database\"]\n",
                "\n",
                "    rel_host = db_config[\"host\"]\n",
                "    rel_port = db_config[\"port\"]\n",
                "    rel_db_name = db_config[\"dbname\"]\n",
                "    rel_user = db_config[\"user\"]\n",
                "    rel_password = db_config[\"password\"]\n",
                "\n",
                "    print(f\"Connecting to database at {rel_host}:{rel_port} as {rel_user}\")\n",
                "    print(f\"Running in Docker: {running_in_docker}\")\n",
                "\n",
                "    return create_engine(f\"postgresql+psycopg2://{rel_user}:{rel_password}@{rel_host}:{rel_port}/{rel_db_name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "engine = create_engine_from_config()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Processing\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Export Tables to CSV\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def export_informative_tables_to_cvs() -> None:\n",
                "    \"\"\"\n",
                "    Reads informative tables from the relational database and exports them to csv files.\n",
                "    \"\"\"\n",
                "    informative_tables = [\"cats\", \"cat_informations\", \"cat_references\", \"breeds\"]\n",
                "\n",
                "    os.makedirs(data_path_initial, exist_ok=True)\n",
                "\n",
                "    for table in informative_tables:\n",
                "        df = pd.read_sql_query(f\"SELECT * FROM {table}\", engine)\n",
                "        for column, dtype in column_types.items():\n",
                "            if column in df.columns and dtype == \"Int64\":\n",
                "                df[column] = df[column].astype(\"Int64\")\n",
                "\n",
                "        df.to_csv(f\"{data_path_initial}/{table}.csv\", index=False)\n",
                "\n",
                "\n",
                "export_informative_tables_to_cvs()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Combine Tables\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def combine_tables_and_export() -> None:\n",
                "    \"\"\"\n",
                "    Merge the informative tables into one table and export it as all_cats.csv.\n",
                "    \"\"\"\n",
                "    cats_df = pd.read_csv(f\"{data_path_initial}/cats.csv\", dtype=column_types, low_memory=False)\n",
                "    cat_informations_df = pd.read_csv(\n",
                "        f\"{data_path_initial}/cat_informations.csv\",\n",
                "        dtype=column_types,\n",
                "        low_memory=False,\n",
                "    )\n",
                "    cat_references_df = pd.read_csv(\n",
                "        f\"{data_path_initial}/cat_references.csv\", dtype=column_types, low_memory=False\n",
                "    )\n",
                "    breeds_df = pd.read_csv(f\"{data_path_initial}/breeds.csv\", dtype=column_types, low_memory=False)\n",
                "\n",
                "    cats_df = cats_df.drop(columns=[\"created_at\", \"updated_at\", \"deleted_at\", \"src_id\"])\n",
                "    cat_informations_df = cat_informations_df.drop(columns=[\"id\"])\n",
                "    cat_references_df = cat_references_df.drop(columns=[\"id\"])\n",
                "\n",
                "    df = pd.merge(cats_df, cat_informations_df, how=\"left\", left_on=\"id\", right_on=\"cat_id\")\n",
                "    df = df.drop(columns=[\"cat_id\"])\n",
                "    df = pd.merge(df, cat_references_df, how=\"left\", left_on=\"id\", right_on=\"cat_id\")\n",
                "    df = df.drop(columns=[\"cat_id\"])\n",
                "    df = pd.merge(df, breeds_df, how=\"left\", left_on=\"breed_id\", right_on=\"id\")\n",
                "    df = df.drop(columns=[\"breed_id\", \"id_y\"])\n",
                "    df = df.rename(columns={\"id_x\": \"id\", \"code\": \"breed_code\"})\n",
                "\n",
                "    df = df.sort_values(by=\"id\")\n",
                "\n",
                "    df.to_csv(f\"{data_path_initial}/all_cats.csv\", index=False)\n",
                "\n",
                "\n",
                "combine_tables_and_export()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "BachelorProject_Babiar",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
